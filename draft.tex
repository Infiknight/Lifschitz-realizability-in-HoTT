\documentclass[12pt]{article}


%\usepackage{answers}

\usepackage{setspace}
%\usepackage{graphicx}
\usepackage{enumitem}
%\usepackage{tikz-cd}
%\usepackage{todonotes}
%\usepackage{multicol}
%\usepackage{mathrsfs}
%\usepackage[margin=1in]{geometry} 
\usepackage{hyperref}% http://ctan.org/pkg/hyperref
\usepackage{cleveref}% http://ctan.org/pkg/cleveref
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{ textcomp }
%\usepackage{ wasysym }
\usepackage{bookmark}
%\usepackage{accents}
\usepackage[parfill]{parskip}

 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\nin}{\not \in}

\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{definition}[2][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{solution}[2][Solution]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\usepackage{xcolor}
\newcommand\todo[1]{\textcolor{red}{#1}}
 
%\newenvironment{bprooftree}
 % {\leavevmode\hbox\bgroup}
  %{\DisplayProof\egroup}

\newtheorem{thm}{Theorem}[section]
\newtheorem{defn}[thm]{Definition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{ill}[thm]{Illustration}
\crefname{thm}{Lemma}{Lemmas}



\begin{document}
 %\pagenumbering{gobble}
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
\title{Draft}%replace with the appropriate homework number
\author{Dimitrios Koutsoulis\\ %replace with your name
11838639} %if necessary, replace with your course title
 
\maketitle
%Below is an example of the problem environment
\section{Type Theory}
\subsection{Introduction}
Type theory is a formal language and deductive system, that is self sufficient in the sense that it need not be formulated as a collection of axioms on top of some other formal system like First Order Logic, instead its deductive system can be built on top of its own formal language. 
\todo{longer sentence to check formating }

Central to Type Theory is the notion of \textit{Type}. Every term $a$ in Type Theory we come across, must lie in some type $A$, which we denote as $a : A$. Note that the relation $:$ is transitive, so $a : A$ and $A : B$ imply $a : B$. 
%This induces the cummulative hierarchy shape of the universe of types $\mathcal{U}$, wherein every level of the universe includes all lower levels and their types.

For the deductive part of Type Theory, we interpret propositions as types. Proving proposition $P$ amounts to providing some inhabitant $p : P$. 

\subsection{Type Construction Operations}
Let's have a look at some important type constructions.
\begin{itemize}
	\item Given types $A, B : \mathcal{U}$ we can define the type $A \rightarrow B$ of functions from $A$ to $B$. 
		We can use $\lambda$-abstraction to construct elements of this type. $\lambda x. \Phi$ lies in $A \rightarrow B$ iff for $a : A$ we have $\Phi[a/x] : B$. 
		For $f : A \rightarrow B$ and $a : A$ we have that the application of $f$ on $a$, denoted as $f(a)$ or $f\;a$, lies in $B$.
	\item Given some type $A : \mathcal{U}$ and a family of types $B$ over $A$, $B : A \rightarrow \mathcal{U}$, we have the type of dependent functions $$\prod_{a : A} B(a)$$
	where for $f : \prod_{a : A} B(a)$ and $x : A$ we have $f(x) : B(x)$. 
	As in the case of non-dependent functions, we can use lambda abstraction to construct elements of a dependently-typed function type.
	\item Given $A, B : \mathcal{U}$ we can define the product type $A \times B : \mathcal{U}$. 
	For $a : A$ and $b : B$ we have the pair $(a,b) : A \times B$. 
	We also have the projection functions 
	$$\mathtt{pr}_1 : A \times B \rightarrow A : (a,b) \mapsto a$$
	$$\mathtt{pr}_2 : A \times B \rightarrow B : (a,b) \mapsto b$$
	\item Given $A : \mathcal{U}$ and family of types $B$ over $A$, $B : A \rightarrow \mathcal{U}$, we can define the dependent pair type $$\sum_{a : A} B(a)$$
	Given $x : A$ and $b : B(x)$ we can construct the pair $(x,b) : \sum_{a : A} B(a)$. 
	We have two projection functions, similar to the case of the product type.
	\item Given $A, B : \mathcal{U}$ we can construct the coproduct type $A + B$. 
	We can construct elements of $A + B$ using the functions
	$$\mathtt{inl} : A \rightarrow A+B$$
	$$\mathtt{inr} : B \rightarrow A+B$$
	This induces the induction principle
	$$\mathtt{ind}_{A+B} : \prod_{C : A+B \rightarrow U} \Big(\prod_{a : A}C(\mathtt{inl}\;a)\Big) \rightarrow \Big(\prod_{b : A}C(\mathtt{inr}\;b)\Big) \rightarrow \prod_{x : A+ B}C(x)$$
	\item Given $x, y : A$ we have the \textbf{identity type} $x =_A y$. 
	An element of this type amounts to a proof that $x$ and $y$ are equal. 
	Say $x$ and $y$ are judgmentally equal. 
	This is captured by the element $\mathtt{idp}_x : x =_A y$. 
	The relevant induction principle describes how we can use elements of an identity type
	$$\mathtt{ind}_{=_{A}} : \prod_{C : \prod_{x,y : A} (x =_A y) \rightarrow \mathcal{U}} \Big( \prod_{x : A}C(x,x,\mathtt{idp}_x) \Big) \rightarrow \prod_{x,y : A} \prod_{(p : x =_A y)} C(x,y,p)$$
	The relevant computation gives us the judgmental equality 
	$$\mathtt{ind}_{=_A} (C,c,x,x,\mathtt{idp_x}) \equiv c\; x$$
	We can concatenate those paths whose domains and codomains allow for it. 
	Paths are equivalences. That is if $p : x = y$ is such a  path, we can provide its inverse $p^{-1}$ for which we have in turn a path between $p\cdot p^{-1}$ and $\mathtt{idp}_y$ and another one between $p^{-1}\cdot p$ and $\mathtt{idp}_x$. 
	\item For every type $A$ there is its \textbf{propositional truncation} $\| A \|$. 
	For every element $a : A$ there exists $|a| : \| A\|$. 
	For every $x, y : \| A\|$ we have $x = y$. 
	Given mere proposition $B$ and $f : A \rightarrow B$, the recursion principle gives us $g : \|A\| \rightarrow B$ such that $g(|a|) \equiv f(a)$ for all $a : A$.


\end{itemize}

\subsection{Important types}
\begin{defn}
We call a type $A$ a \textbf{mere proposition} if for every $a,b : A$ we have $a = b$.
\end{defn}

\begin{defn}
We call a type $A$ a \textbf{set} if for every $a,b : A$ we have that $a =_A b$ is a mere proposition.
\end{defn}

\begin{defn}
We call a type $A$ \textbf{contractible} if there exists $a : A$ such that for all $x : A$ it holds that $x = a$.
\end{defn}

\subsection{Logic}
Our informal deductions in Type Theory will be reminiscent of First Order Logic ones. 
To be able to use a similar verbiage, we will set down a handful of types, corresponding to the connectives that let us form well-formed formulas in FOL. 
These types need to be mere propositions, so that we can form non-constructive deductions. 
This approach is called `propositions as h-propositions' in the HoTT book. 
In the following, $A$ and $B$ are mere propositions.
\begin{itemize}
\item When we talk of conjunction $A \wedge B$, we mean the product $A \times B$. 
\item We interpret $A \vee B$, as the truncation $\| A + B\|$.
\item We interpret $\forall a\in A,\; P(a)$, where $P(a)$ is a mere proposition for all $a \in A$, as $\prod_{a : A}P(a)$. 
\item We interpret $ \exists a \in A,\; P(a)$, where $P(a)$ is a mere proposition for all $a \in A$, as $\| \Sigma_{a : A} P(a) \|$
\end{itemize}
The use of the above notation is interchangeable in the sections to follow.


\section{Modalities}
%Under the view of types as $(\infty, 1)$-categories, functions between them are functors. 
%We can then view the universe $\mathcal{U}$ itslef as a category. 
\begin{defn}
A \textbf{modality} is a function $\bigcirc : \mathcal{U} \rightarrow \mathcal{U}$ with the following properties.
\begin{enumerate}
	\item For every type $A$ we have a function $\eta_A^\bigcirc : A \rightarrow \bigcirc\; A$
	\item for every $A : \mathcal{U}$ and every type family $B : \bigcirc A \rightarrow \mathcal{U}$ we have a function
	$$\mathtt{ind}_\bigcirc : \Big( \prod_{a : A}\bigcirc (B (\eta_A^\bigcirc\; a)) \Big) \rightarrow \prod_{z : \bigcirc A} \bigcirc (B\; z)$$
	\item For every $f : \prod_{a : A} \bigcirc (B(\eta_A^\bigcirc\; a))$ there is a path $\mathtt{ind}_\bigcirc (f)(\eta_A^\bigcirc\; a) = f\; a$
	\item For all $z,z' : \bigcirc \; A$, the function $\eta_{z=z'}^\bigcirc : (z = z') \rightarrow \bigcirc (z = z')$ is an equivalence.

\end{enumerate}
\end{defn}
A modality $\bigcirc$ induces a $\Sigma$-closed reflective subuniverse.

\begin{defn}
Given modality $\bigcirc : \mathcal{U} \rightarrow \mathcal{U}$, a \textbf{reflective subuniverse} is a `subset' of $\mathcal{U}$ encoded by a family of h-propositions $P : \mathcal{U} \rightarrow \mathtt{Prop}$ such that the following conditions hold. 
\begin{itemize}
	\item For $A : \mathcal{U}$, we have $P(\bigcirc A)$.
	\item For $A : \mathcal{U}$ and $B$ such that $P(B)$, the function
	$$\lambda f.f \circ \eta_A^\bigcirc : (\bigcirc A \rightarrow B) \rightarrow (A \rightarrow B)$$
	is an equivalence.

\end{itemize}
The subuniverse is $\Sigma$\textbf{-closed} if for $X$ such that $P(X)$ and $Q : X \rightarrow \mathcal{U}$ such that $\prod_{x : X} P(Q(x))$, we have $P(\Sigma_{x : X} Q(x))$.
\end{defn}

\begin{thm}
Reflective subuniverses are closed under products. 
That is for subuniverse $P$ and $B : A \rightarrow \mathcal{U}$ such that $\prod_{a : A}P(B(a))$, we have that $P(\prod_{a : A} B(a))$. 
\end{thm}

\begin{proof}
For $a : A$, consider $\mathtt{ev}_a: (\prod_{a: A}B(a)) \rightarrow B(a)$ defined by $\mathtt{ev}_a (f) : \equiv f(x)$. 
Since $P(B(a))$, we have 
$$(\lambda f.f \circ \eta_{\prod_{a: A}B(a)}^\bigcirc)^{-1} (\mathtt{ev}_a) : \bigcirc\big(\prod_{a: A}B(a)\big) \rightarrow B(a)$$
We can now define the retraction of $\eta^\bigcirc_{\prod_{a : A} B(a)}$ by pattern matching as such:\\
For $z: (\prod_{a: A}B(a))$ and $a : A$ we have 
$$(\lambda f.f \circ \eta_{\prod_{a: A}B(a)}^\bigcirc)^{-1} (\mathtt{ev}_a) (z) : B(a)$$

\end{proof}

\begin{defn}
For $B : A \rightarrow \mathcal{U}$, we call $X$ $B$\textbf{-null} if the map 
$$\lambda x. \lambda b.x : X \rightarrow (B(a) \rightarrow X)$$
is an equivalence for all $a : A$.

\end{defn}

\section{LLPO}
\begin{defn} 
The Lesser Limited Principle of Omniscience, states that given binary sequence $s : \mathbb{N} \rightarrow \mathbf{2}$ and the fact that there is at most one occurence of $1$ in the sequence, formally 
$$\mathtt{atMost1one} :\prod_{n_1 : \mathbb{N}} \prod_{n_2 : \mathbb{N}} s(n_1) = 1 \rightarrow s(n_2)= 1 \rightarrow n_1 = n_2$$
we can then have by the LLPO a witness for $\mathtt{p_{odd}} \vee \mathtt{p_{even}}$, where $\mathtt{p_{odd}}$ (with $s$ as an implicit argument) is the statement that for all odd positions $n$, $s(n) = 0$, formally $\mathtt{p_{odd}} \equiv \prod_{n : \mathbb{N}} \mathtt{odd}(n) \rightarrow s(n) = 0$. 
Similarly for $\mathtt{p_{even}}$. 
\end{defn}
LLPO can be viewed as a weaker form of the Law of Excluded Middle. 

\begin{lem} 
The Law of Excluded Middle implies the Lesser Limited Principle of Omniscience.
\end{lem}

\begin{proof}
By LEM we have a witness $ l_1 :\mathtt{p_{odd}} \vee \neg \mathtt{p_{odd}}$. 
Since this is a coproduct, by the relevant principle of induction, it's enough to prove LLPO from the disjuncts. 
\begin{itemize}
	\item $\mathtt{p_{odd}} \Rightarrow $ LLPO, trivially.

	\item $\neg \mathtt{p_{odd}}$, alongside LEM, implies that there exists odd $n_e : \mathbb{N}$ such that $s(n_e) = 1$. 
	We can now provide $\prod_{n : \mathbb{N}} \mathtt{even}(n) \rightarrow s(n) = 0$. 
	Let $n : \mathbb{N}$. 
	By the definition of $s$, $s(n) = 0 \vee s(n) = 1$.
	We invoke the principle of induction of coproducts and prove LLPO from the disjuncts. 
	\begin{itemize}
		\item $s(n) = 0$, in this case we are done.
		\item $s(n) = 1$. 
		By $\mathtt{atMost1one}$ we have $n = n_e \Rightarrow $ $n$ even and odd which is a contradiction $c : \bot$. 
		Ex Falso,  $\mathtt{efq} : \bot \rightarrow s(n) = 0$. 
		Then $\mathtt{efq}(c) : s(n) = 0$.
	\end{itemize}
\end{itemize}
\end{proof}

\begin{lem}\label{llponeg}
If we replace the consequent of LLPO with its double negation, let's call it $\neg\neg$LLPO, then we can prove it in Type Theory. 
\end{lem}
\begin{proof}
From LEM$\;\Rightarrow\;$LLPO we have LEM$\;\Rightarrow\neg\neg$LLPO by effectively the same proof. 
Since we invoke LEM only finitely many times, we can use their finite conjunction to prove $\neg\neg$LLPO. 
The double negations of those instances are provable in Type Theory \todo{(include the proof of this?)}.
We can leverage the fact that double negation is a modality, to construct a function that assumes the double negations of the LEM instances and concludes $\neg\neg$LLPO.
\end{proof}

\section{Extensional Type Theory}
There exists a model of extensional type theory that validates the following `Independence Principle'
$$\bigg( \prod_{s : \mathbf{2}^\mathbb{N}} P\; s \rightarrow \Big(\prod_{n : \mathbb{N}}s\; n = 0 \Big) \rightarrow \Big\lVert \sum_{z : \mathbb{N}} Q\; s\; z \Big\rVert \bigg)$$
$$\rightarrow \bigg( \prod_{s : \mathbf{2}^\mathbb{N}} P\; s \rightarrow  \Big\lVert \sum_{z : \mathbf{2}} \Big(\prod_{n : \mathbb{N}}s\; n = 0 \Big) \rightarrow Q \; s\; z\Big\rVert \bigg)$$
where $P: \mathbf{2}^\mathbb{N} \rightarrow \mathtt{Prop}$ and $Q : \mathbf{2}^\mathbb{N} \rightarrow \mathbb{N} \rightarrow \mathtt{Prop} $ are families of propositions. 
Putting it plainly, if the left hand side of the above is true, then $z : \mathbb{N}$ does not depend on the proof of the constantness of $s$ to $0$.

The same model also validates Markov's Principle
$$\Big(\prod_{a : A}(P\; a \vee \neg P\; a)\Big) \rightarrow  \Big(\neg \prod_{a : A}\neg P\; a\Big)\rightarrow \Big\lVert \sum_{a : A} P\; a \Big\rVert$$
where $P : A \rightarrow \mathtt{Prop}$ is a family of propositions over $A : \mathcal{U}$. 
Informally, Markov's Principle states that if we have a collection of decidable propositions and the fact that not all of them are false, then one of them must be true.

In this section we will be working in the context of this model.

Let $A :\equiv \sum_{a: \mathbf{2}^\mathbb{N}}\mathtt{atMost1one}\;a$. 
When referring to elements of $A$ we implicitly mean the first part of the pair. 
Let
$$B : A \rightarrow \mathtt{Prop}$$
$$B :\equiv \lambda\; a.\; \mathtt{p_{odd}}\; a \vee \mathtt{p_{even}}\; a$$
\begin{lem}
$\mathbb{N}$ is $B$-null.
\end{lem}
\begin{proof}
Given $a : A$ and $f : B\; a \rightarrow \mathbb{N}$ we need to prove that there exists unique $f' : \mathbf{1} \rightarrow \mathbb{N}$ through which $f$ factors, in the sense that $f = f' \circ g$, where $g : B\; a \rightarrow \mathbf{1}$ is the sole inhabitant of its function space. 
Functions with $\mathbf{1}$ as their domain are constant. 
We therefore need to find some $z : \mathbb{N}$ so that $\lambda\; \_.\; z$ is $f'$. 
To that end, we will use the following instance of the Independence Principle
$$\bigg( \prod_{s : \mathbf{2}^\mathbb{N}} \Big(\big(\prod_{n : \mathbb{N}} s(n) = a(2 \cdot n)\big) \vee \big(\prod_{n : \mathbb{N}} s(n) = a(2\cdot n +1)\big) \Big) \rightarrow \Big(\prod_{n : \mathbb{N}}s\; n = 0 \Big) \rightarrow \Big\lVert \sum_{z : \mathbb{N}}\prod_{p : B\; a} f\; p = z\Big\rVert \bigg)$$
$$\rightarrow \bigg( \prod_{s : \mathbf{2}^\mathbb{N}} \Big(\big(\prod_{n : \mathbb{N}} s(n) = a(2 \cdot n)\big) \vee \big(\prod_{n : \mathbb{N}} s(n) = a(2\cdot n +1)\big) \Big) \rightarrow  \Big\lVert \sum_{z : \mathbb{N}} \Big(\prod_{n : \mathbb{N}}s\; n = 0 \Big) \rightarrow\prod_{p : B\; a} f\; p = z\Big\rVert \bigg)$$
Note that the left hand side is provable. 
By providing the odd $s_1$ and even $s_2$ subsequences of $a$ to the right hand side, we get hold of $z_1 : \mathbb{N}$ and $z_2 : \mathbb{N} $ respectively. 
Equality on $\mathbb{N}$ is decidable, therefore $z_1 = z_2 \vee z_1 \neq z_2$ is provable. 
Since our goal is a proposition, we can drop the truncation of the disjunction. 
This leaves us with a coproduct. 

We will first prove that the existence of a candidate for $f'$ follows from both constituents of the coproduct.
\begin{itemize}
\item First the case where $z_1= z_2$. 
We arbitrarily pick $z_1$ and propose $f' : \equiv \lambda \;\_.\; z_1$. 
By axiom K we have function extensionality, so we reduce proving $f= f' \circ g$ to proving $f\; b = f'\circ g\; b$ for arbitrary $b : B\; a$. \\
$b$ is a truncated coproduct witness. 
As before we can ignore the truncation and take cases on the coproduct. 
\begin{itemize}
\item We first consider the case $\mathtt{p_{odd}}\; a$. 
This tells us that the odd subsequence is constantly $0$, which we can provide to the rhs of the IP alongside with $b$  itself (and $s_1$ as the first argument) to get $f\; = z_1$. We concatenate this with $f' \circ g \; b = z_1$ to conclude this case. 
\item The $\mathtt{p_{even}}$ case is very similar. 
The only difference is that we provide $s_2$ as the first argument to the rhs of the IP and then have $z_1=z_2$ be part of the concatenation of paths when we prove homotopy between $f$ and $f' \circ g$. 
\end{itemize}

\item Now consider the case $z_1 \neq z_2$. 
For any $n : \mathbb{N}$, $a\; n = 1$ is decidable. 
Suppose that $\prod_{n : 
\mathbb{N}} a\; n \neq 1$. 
Then $a$ and by extension $s_1$ and $s_2$ are constantly $0$. 
By the rhs of the IP we then have $z_1 = f\; b = z_2$ where $b : B\; a$ is clearly available to us at this point. 
This contradicts $z_1 \neq z_2$. 
We have proven $\neg \prod_{n : 
\mathbb{N}} a\; n \neq 1$. 
By Markov's Principle there exists $n_1 : \mathbb{N}$ such that $a\; n_1 = 1$. 
We pick the subsequence $s_0$ with parity opposite to $n_1$ and let $f'$ be always equal to the corresponding $z_0$. 
We prove $\prod_{n : \mathbb{N}} s_0\; n = 0$ by induction on $\mathbb{N}$ and cases on $s_0 \;n$. 
In the case where $s_0\; n = 1$ we can reach falsum because $n$ will have to be both even and odd (in $a$) by $\mathtt{atMost1one} \; a$. Ex falso trivializes this case. 
Now that we have established this too, we have enough arguments for the rhs of IP to output the desired equality $f\; b = z_0$ which proves homotopy between $f$ and $(\lambda\;\_.\; z_0) \circ g$.
\end{itemize}
We still need to prove the uniqueness of $f'$. 
Since $\mathbf{1}$ is finite and equality on $\mathbb{N}$ is decidable, we can decide equality on the function space 
$$p : \prod_{f_1,f_2 : \mathbf{1}\rightarrow \mathbb{N}} f_1 = f_2 + f_1 \neq f_2$$
We will use this to prove that $\sum_{h : \mathbf{1}\rightarrow \mathbb{N}} f= h \circ g$ is a mere proposition, which entails the uniqueness of $f'$. 
Consider $h_1,h_2 : \mathbf{1}\rightarrow \mathbb{N}$ such that $f= h_i \circ g,\; i \in \{1,2\}$. 
By $p$ we have $(h_1 = h_2) + (h_1 \neq h_2)$. 
We use induction on the coproduct. 
The left case is trivial. 
For the right case we have $q : h_1 \neq h_2$ and we will first try to prove $B\; a \rightarrow \bot$ as a stepping stone. 
Consider $b : B\; a$. 
Since $h_1 \circ g = f = h_2 \circ g$, by homotopy $h_1 (g\; b) = h_2 (g\; b)$. 
We can then prove $\prod_{*: \mathbf{1}} h_1 (*) = h_2 (*)$. 
By function extensionality $h_1 = h_2$. 
But this contradicts $q$, so we reach $\bot$. 
We've just proven $r : B\;a \rightarrow \bot$. 
We still have to prove $h_1 = h_2$, the main goal. 
By \cref{llponeg} we have $(B\; a \rightarrow \bot) \rightarrow \bot$ and by $r$ we get $\bot$. 
We conclude the proof by Ex Falso.
\end{proof}

\end{document}

